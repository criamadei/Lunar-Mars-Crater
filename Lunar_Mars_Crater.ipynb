{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNkd34SsxDkz7notPveFrvE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/criamadei/Lunar-Mars-Crater/blob/main/Lunar_Mars_Crater.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1666d0c3"
      },
      "source": [
        "## Lunar and Martian Crater Detection with YOLOv8\n",
        "\n",
        "This project demonstrates the use of YOLOv8 (You Only Look Once, version 8) for detecting craters on Martian and Lunar surfaces. Leveraging a dataset specifically curated for crater identification, the model is trained to accurately pinpoint these geological features, which are crucial for planetary science, landing site selection, and understanding celestial body evolution.\n",
        "\n",
        "### Project Workflow:\n",
        "\n",
        "1.  **Environment Setup**: Installation of necessary libraries, including `ultralytics` for YOLOv8.\n",
        "2.  **Hardware Check**: Verification of GPU availability to accelerate training.\n",
        "3.  **Data Acquisition**: Downloading and extraction of the \"Martian Lunar Crater Detection Dataset\" from Kaggle.\n",
        "4.  **Dataset Configuration**: Creation and refinement of a `craters.yaml` file to properly map dataset paths for YOLOv8.\n",
        "5.  **Model Training**: Training a YOLOv8s model with custom hyperparameters for improved detection performance.\n",
        "6.  **Results Analysis**: Visualization of training metrics (loss curves, precision, recall) and confusion matrix.\n",
        "7.  **Visual Inference**: Demonstrating the trained model's detection capabilities on sample images.\n",
        "8.  **Model Export**: Providing the option to download the best-trained model weights.\n",
        "9.  **GIF Generation**: Creating an animated GIF to visually showcase the model's real-time detection in action.\n",
        "\n",
        "This notebook provides a complete pipeline from data preparation to model deployment and visualization for an object detection task in a specialized domain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X8vCDEghCBSU"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# ==========================================\n",
        "# 1. CONFIGURATION\n",
        "# ==========================================\n",
        "!pip install -q --upgrade pip\n",
        "!pip install -q pandas numpy matplotlib seaborn scikit-learn ultralytics\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 2. SETUP AND IMPORT\n",
        "# ==========================================\n",
        "\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Graph style configuration (Pro-tip: makes everything more readable)\n",
        "sns.set_theme(style=\"whitegrid\", context=\"notebook\")\n",
        "plt.rcParams['figure.figsize'] = (10, 6) # Set standard dimension for graph\n",
        "%matplotlib inline\n",
        "\n",
        "print(\"‚úÖ Libraries imported and graph style configured.\")"
      ],
      "metadata": {
        "id": "7m4RJrk4CnXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 3. HARDWARE CHECK (GPU)\n",
        "# ==========================================\n",
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"‚úÖ GPU Found: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"   GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Warning: GPU not found. The code will run on CPU (slower).\")\n",
        "    print(\"   Tip: Go to Runtime > Change runtime type > T4 GPU\") #in Colab settings"
      ],
      "metadata": {
        "id": "V02enqrwDDct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 4. SETTING SEED\n",
        "# ==========================================\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    print(f\"‚úÖ Random seed set to: {seed}\")\n",
        "\n",
        "set_seed(42)"
      ],
      "metadata": {
        "id": "bKzQokhJDdPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 5. KAGGLE AUTH (SECURE)\n",
        "# ==========================================\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "try:\n",
        "    os.environ['KAGGLE_USERNAME'] = userdata.get('KAGGLE_USERNAME')\n",
        "    os.environ['KAGGLE_KEY'] = userdata.get('KAGGLE_KEY')\n",
        "    print(\"‚úÖ Kaggle credential loaded from Secrets.\")\n",
        "except Exception as e:\n",
        "    print(\"‚ùå Error: Set 'KAGGLE_USERNAME' and 'KAGGLE_KEY' in Colab Secrets.\")"
      ],
      "metadata": {
        "id": "56KjYrTAEyi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 6. DOWNLOAD DATASET (Mars/Moon Object Detection)\n",
        "# ==========================================\n",
        "import os\n",
        "\n",
        "dataset_slug = \"lincolnzh/martianlunar-crater-detection-dataset\"\n",
        "\n",
        "# Download\n",
        "if not os.path.exists('martianlunar-crater-detection-dataset.zip'):\n",
        "    print(f\"‚¨áÔ∏è Downloading {dataset_slug}...\")\n",
        "    !kaggle datasets download -d $dataset_slug\n",
        "    !unzip -q martianlunar-crater-detection-dataset.zip -d dataset_mars_moon\n",
        "    print(\"‚úÖ Download done.\")\n",
        "else:\n",
        "    print(\"‚úÖ Dataset already present.\")"
      ],
      "metadata": {
        "id": "RL_VaTX7FKov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 7. CONFIGURAZIONE DATASET (YAML)\n",
        "# ==========================================\n",
        "import yaml\n",
        "\n",
        "# Define the absolute path where we extracted the data\n",
        "base_dir = '/content/dataset_mars_moon'\n",
        "\n",
        "# Try to understand the internal structure (often Kaggle datasets have subfolders 'images' or 'martian_lunar...')\n",
        "# For this specific dataset, the structure usually has mixed images and labels or separate folders.\n",
        "# Create a yaml file that points to the correct folders.\n",
        "\n",
        "# YOLO expects this structure in the yaml file:\n",
        "data_config = {\n",
        "    'path': base_dir,         # Root folder\n",
        "    'train': 'images',        # Training images subfolder (or relative path)\n",
        "    'val': 'images',          # Use the same for validation if there's no separate folder (or do split)\n",
        "    'names': {0: 'Crater'}    # Class name\n",
        "}\n",
        "\n",
        "# IMPORTANT NOTE:\n",
        "# Often this specific LincolnZh dataset has a somewhat disorganized structure.\n",
        "# If you see \"No images found\" errors, you might need to move the files.\n",
        "# This standard procedure tries to configure it:\n",
        "\n",
        "with open('craters.yaml', 'w') as f:\n",
        "    yaml.dump(data_config, f, default_flow_style=False)\n",
        "\n",
        "print(\"‚úÖ File 'craters.yaml' created. YOLO will know where to search.\")\n",
        "print(\"‚ö†Ô∏è WARNING: If training fails, check the 'dataset_mars_moon' folder on the left.\")"
      ],
      "metadata": {
        "id": "GVC-v_swFWWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# ==========================================\n",
        "# 8. TRAINING YOLOv8\n",
        "# ==========================================\n",
        "from ultralytics import YOLO\n",
        "import yaml # Import yaml to re-create the config file\n",
        "import os   # Import os to use base_dir\n",
        "\n",
        "# 1. Load a pre-trained model (Nano = very fast, Small = more accurate)\n",
        "model = YOLO('yolov8s.pt')  # Automatically downloads the initial weights\n",
        "\n",
        "# --- FIX START ---\n",
        "# The original craters.yaml was configured incorrectly.\n",
        "# Redefine the base directory and correct the paths for images and labels.\n",
        "base_dir = '/content/dataset_mars_moon'\n",
        "\n",
        "data_config = {\n",
        "    'path': os.path.join(base_dir, 'craters'), # The root for train/val/test is inside 'craters' folder\n",
        "    'train': 'train/images',\n",
        "    'val': 'valid/images',\n",
        "    'test': 'test/images', # It's good practice to include the test set path if available\n",
        "    'names': {0: 'Crater'}\n",
        "}\n",
        "\n",
        "# Overwrite the existing 'craters.yaml' with the corrected paths\n",
        "with open('craters.yaml', 'w') as f:\n",
        "    yaml.dump(data_config, f, default_flow_style=False)\n",
        "\n",
        "print(\"‚úÖ File 'craters.yaml' updated with correct paths.\")\n",
        "# --- FIX END ---\n",
        "\n",
        "# 2. Start training\n",
        "# epochs=20: Number of epochs\n",
        "# imgsz=640: Image size (YOLO standard)\n",
        "# data='craters.yaml': The file we created above\n",
        "print(\"üöÄ Starting YOLOv8 training...\")\n",
        "\n",
        "results = model.train(\n",
        "    data='craters.yaml',\n",
        "    epochs=100,\n",
        "    patience=10,\n",
        "    imgsz=1240,\n",
        "    batch=16,\n",
        "    dropout=0.3,\n",
        "    freeze=10,\n",
        "\n",
        "    degrees=180.0,\n",
        "    flipud=0.5,\n",
        "    fliplr=0.5,\n",
        "    mosaic=1.0,\n",
        "    mixup=0.1,\n",
        "\n",
        "    optimizer='AdamW',\n",
        "    lr0=0.001,\n",
        "    cos_lr=True,\n",
        "    project='lunar_crater_project',\n",
        "    name='yolo_run',\n",
        "    exist_ok=True\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Training completed!\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "YmbZTfvnNvs-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 8-BIS. TRAINING COMPLETION CONFIRMATION\n",
        "# ==========================================\n",
        "print(\"‚úÖ Training completed in background!\")\n",
        "print(f\"Results are saved in: {results.save_dir}\")\n",
        "\n",
        "# Show the final result (mAP) immediately to see how it went\n",
        "metrics = model.val() # Calculate final metrics\n",
        "print(f\"\\nüéØ Final mAP50: {metrics.box.map50:.4f}\")\n",
        "print(f\"üéØ Final mAP50-95: {metrics.box.map:.4f}\")"
      ],
      "metadata": {
        "id": "e1JC6HwKdu_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35989f13"
      },
      "source": [
        "### Results Analysis Summary\n",
        "\n",
        "The training process was successfully completed. Below, you can observe the learning curves for various metrics (Loss, Precision, Recall) and the Confusion Matrix generated during the training of the YOLOv8 model for crater detection.\n",
        "\n",
        "*   **Loss Curves**: These graphs illustrate how the model's error (loss) decreased over epochs, indicating that the model was learning and converging.\n",
        "*   **Precision and Recall Curves**: These show the trade-off between precision (accuracy of positive predictions) and recall (ability to find all positive samples) as training progressed. Ideally, both should increase and stabilize at high values.\n",
        "*   **Confusion Matrix**: This visualizes the performance of the classification model, showing true positives, true negatives, false positives, and false negatives. For single-class detection like 'Crater', it primarily indicates how well craters are detected versus background.\n",
        "\n",
        "The overall metrics (mAP50, mAP50-95) provide a quantitative measure of the model's accuracy in detecting craters. Further analysis of these plots can help identify potential areas for improvement, such as adjusting hyperparameters or augmenting the dataset."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 9. RESULT ANALYSIS\n",
        "# ==========================================\n",
        "from IPython.display import Image, display\n",
        "\n",
        "# Path generated by YOLO (based on project='lunar_crater_project' and name='yolo_run')\n",
        "# If you changed the names in the previous cell, update here too.\n",
        "results_path = 'lunar_crater_project/yolo_run/results.png'\n",
        "confusion_matrix_path = 'lunar_crater_project/yolo_run/confusion_matrix.png'\n",
        "\n",
        "print(\"üìä Learning curves (Loss, Precision, Recall):\")\n",
        "try:\n",
        "    display(Image(filename=results_path, width=800))\n",
        "except:\n",
        "    print(\"‚ö†Ô∏è Graphic results.png not found. Check the directory.\")\n",
        "\n",
        "print(\"\\nüß© Confusion Matrix (How much the model gets confused):\")\n",
        "try:\n",
        "    display(Image(filename=confusion_matrix_path, width=600))\n",
        "except:\n",
        "    print(\"‚ö†Ô∏è Confusion matrix not found.\")"
      ],
      "metadata": {
        "id": "mY_qwUkfPQHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 10. TEST VISIVO (INFERENZA)\n",
        "# ==========================================\n",
        "import glob\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "# Take 3 random images from the test/validation folder\n",
        "# Note: Adjust the path if your images are in a different subfolder\n",
        "test_images = glob.glob('dataset_mars_moon/**/*.jpg', recursive=True)\n",
        "# Take a random subset\n",
        "sample_images = random.sample(test_images, 3)\n",
        "\n",
        "# Load the best model obtained from training\n",
        "best_model = YOLO('lunar_crater_project/yolo_run/weights/best.pt')\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "for i, img_path in enumerate(sample_images):\n",
        "    # Execute the prediction\n",
        "    results = best_model.predict(source=img_path, conf=0.25, verbose=False) # conf=0.25 is the confidence threshold\n",
        "\n",
        "    # YOLO has an internal function to draw boxes\n",
        "    res_plotted = results[0].plot()\n",
        "\n",
        "    # Convert from BGR (OpenCV) to RGB (Matplotlib) to see it with correct colors\n",
        "    res_plotted = cv2.cvtColor(res_plotted, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    plt.subplot(1, 3, i + 1)\n",
        "    plt.imshow(res_plotted)\n",
        "    plt.axis('off')\n",
        "    plt.title(f\"Test Image {i+1}\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QqxGxlwwPSKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 11. EXPORT DEL MODELLO\n",
        "# ==========================================\n",
        "from google.colab import files\n",
        "\n",
        "try:\n",
        "    print(\"‚¨áÔ∏è Downloading the best model (best.pt)...\")\n",
        "    files.download('lunar_crater_project/yolo_run/weights/best.pt')\n",
        "except Exception as e:\n",
        "    print(\"Could not download the file automatically.\")\n",
        "    print(\"You can find it on the left at: lunar_crater_project/yolo_run/weights/best.pt\")"
      ],
      "metadata": {
        "id": "5ab2BRMFPUPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 12. GIF GENERATOR\n",
        "# ==========================================\n",
        "import imageio\n",
        "import glob\n",
        "import random\n",
        "import cv2\n",
        "import os\n",
        "from IPython.display import Image, display\n",
        "\n",
        "print(\"üé¨ Creazione della GIF dimostrativa...\")\n",
        "\n",
        "# 1. Load the best model\n",
        "# Make sure the path is correct (you can find it in the folder on the left)\n",
        "model_path = 'lunar_crater_project/yolo_run/weights/best.pt'\n",
        "\n",
        "# 2. Take 15 random images from the dataset\n",
        "all_images = glob.glob('dataset_mars_moon/**/*.jpg', recursive=True)\n",
        "selected_images = random.sample(all_images, 15)\n",
        "\n",
        "frames = []\n",
        "\n",
        "for img_path in selected_images:\n",
        "    # Execute the prediction\n",
        "    results = model.predict(img_path, conf=0.25, verbose=False)\n",
        "\n",
        "    # Draw boxes on the image\n",
        "    res_plotted = results[0].plot()\n",
        "\n",
        "    # Convert colors from BGR (OpenCV) to RGB (Standard)\n",
        "    res_plotted = cv2.cvtColor(res_plotted, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Add to the frames list\n",
        "    frames.append(res_plotted)\n",
        "\n",
        "# 3. Save the GIF\n",
        "gif_path = \"crater_detection_demo.gif\"\n",
        "# duration=500 means 500ms per frame (2 frames per second), loop=0 is infinite\n",
        "imageio.mimsave(gif_path, frames, duration=500, loop=0)\n",
        "\n",
        "print(f\"‚úÖ GIF salvata come: {gif_path}\")\n",
        "\n",
        "# 4. Display it here immediately\n",
        "display(Image(filename=gif_path, width=600))"
      ],
      "metadata": {
        "id": "X_juckvWaNSz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}